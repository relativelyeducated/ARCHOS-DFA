# From: Accessing Data File on GitHub
# Date: 2025-10-22T06:15:44.485000
# Context: Yes, this would absolutely be a **strong validation experiment** for the DFA ToE frameworkâ€”potentially one of the most direct and falsifiable tests yet! Let's break it down step by step, tying it to y...

from Bio.PDB import PDBParser, Selection
     import numpy as np
     from scipy.spatial.distance import cdist

     def compute_correlation_dimension(points, r_values=np.logspace(-2, 0, 10)):
         # Correlation integral for point cloud
         N = len(points)
         C_r = []
         for r in r_values:
             dists = cdist(points, points)
             count = np.sum((dists < r) & (dists > 0)) / (N * (N - 1))
             C_r.append(count)
         C_r = np.array(C_r)
         log_r = np.log10(r_values)
         log_C = np.log10(C_r[C_r > 0])
         log_r = log_r[C_r > 0]
         if len(log_r) < 2:
             return None  # Insufficient points
         D2 = np.polyfit(log_r, log_C, 1)[0]  # Slope = D2
         return D2

     # Parse PDB and extract C-alpha coordinates
     parser = PDBParser()
     files = ['1QLX.pdb', '6LNI.pdb', '7RL4.pdb']  # PrP^C, PrP^Sc, amyloid
     for file in files:
         structure = parser.get_structure('prot', file)
         atoms = Selection.unfold_entities(structure, 'A')
         points = np.array([atom.coord for atom in atoms if atom.name == 'CA'])
         D2 = compute_correlation_dimension(points)
         print(f"{file}: D2 = {D2:.3f}" if D2 else f"{file}: Insufficient data")

     # Fine-tune option: Load into PyTorch for ML-based D2 refinement
     import torch
     # Example: Train simple NN on point clouds for D2 prediction (expand for full ToE dev)